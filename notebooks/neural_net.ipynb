{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Dense\n",
    "import category_encoders as ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"flight_data_weather.csv\"\n",
    "filepath = \"../data/\"\n",
    "flight_df = pd.read_csv(filepath + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_df.columns\n",
    "# flight_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing dimensionality of Carrier with custom grouping\n",
    "value_counts = flight_df['Carrier'].value_counts()\n",
    "to_remove = value_counts[value_counts <= 9000].index\n",
    "flight_df['Carrier'].replace(to_remove, 'Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing dimensionality of TimeZones \n",
    "def binary_encode_timezone(df, columns):\n",
    "    encoder = ce.BinaryEncoder(cols=columns)\n",
    "\n",
    "    # Fit and transform to produce binary encoded data\n",
    "    df_encoded = encoder.fit_transform(df[columns])\n",
    "\n",
    "    # Merge the encoded data back with the original DataFrame\n",
    "    df = df.drop(columns, axis=1)\n",
    "    df = pd.concat([df, df_encoded], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model run 1\n",
    "\n",
    "Timezones instead of airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', \n",
    "'Dest', 'Origin', 'Distance', 'Carrier',\n",
    "'Full-time', 'Part-time', 'Grand Total', 'CRSArrTime', 'CRSElapsedTime',\n",
    "'Origin_Windspeed', 'Origin_Precip', 'Dest_Windspeed', 'Dest_Precip', 'dest_ianaTimeZone',\n",
    "'origin_ianaTimeZone', 'Aircraft_Daily_Flight_Count']\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = flight_df['ArrDel15']\n",
    "X = flight_df[features]\n",
    "\n",
    "# Encoding categorical variables\n",
    "X = binary_encode_timezone(X, ['origin_ianaTimeZone', 'dest_ianaTimeZone', 'Dest', 'Origin'])\n",
    "X = pd.get_dummies(X, columns=['Carrier'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # or 'softmax' for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "# Test accuracy: 0.8716484308242798"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model run 2\n",
    "\n",
    "Airport Dest and Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', \n",
    "       'DepTime', 'Dest', 'DepDelay','ArrTime',\n",
    "       'Distance', 'Carrier', 'Origin', 'Origin_Windspeed', 'Origin_Precip', \n",
    "       'Dest_Windspeed', 'Dest_Precip', 'dest_ianaTimeZone',\n",
    "       'origin_ianaTimeZone', 'Aircraft_Daily_Flight_Count']\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = flight_df['ArrDel15']\n",
    "X = flight_df[features]\n",
    "\n",
    "# Encoding categorical variables\n",
    "X = binary_encode_timezone(X, ['origin_ianaTimeZone', 'dest_ianaTimeZone', 'Dest', 'Origin'])\n",
    "X = pd.get_dummies(X, columns=['Carrier'])\n",
    "# X = label_encode_airport_codes(X)\n",
    "print(f\"Shape after encoding: {X.shape}\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # or 'softmax' for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "# Test accuracy: 0.860675573348999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing neural net params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # or 'softmax' for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "# Test accuracy: 0.8750291466712952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More layer testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # or 'softmax' for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "# loss: 0.2428 - accuracy: 0.8953 - val_loss: 0.2410 - val_accuracy: 0.8953"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "# from tf.keras.optimizers.legacy.Adam import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "    # Set your desired learning rate\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    # Create an Adam optimizer with the set learning rate\n",
    "    adam_optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(params['first_hidden_layer_neurons'], activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(params['middle_hidden_layer_neurons'], activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=int(params['batch_size']), validation_split=0.2, verbose=0)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"For training run with params: {params}. Loss: {loss}, Accuracy: {accuracy}\")\n",
    "    return loss\n",
    "\n",
    "space = {\n",
    "    'batch_size': hp.choice('batch_size', [32, 64]),\n",
    "    'first_hidden_layer_neurons': hp.choice('first_hidden_layer_neurons', [64, 128, 256, 512]),\n",
    "    'middle_hidden_layer_neurons': hp.choice('middle_hidden_layer_neurons', [32, 64, 128, 256]),\n",
    "    'learning_rate': hp.choice('learning_rate', [0.001, 0.0001, 0.00001]),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective_function,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=Trials())\n",
    "\n",
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
