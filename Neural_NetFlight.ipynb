{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NedKost/MS-AAI-501-Team-Project/blob/main/Neural_NetFlight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJxCDhR_q2Sm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/Users/anovayoungers/Downloads/flight_data.csv'\n",
        "data = pd.read_csv(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfDM3AePq2Sm",
        "outputId": "3a86fa4a-ad2a-4ba8-f66d-05e44b716d5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17412876 entries, 0 to 17412875\n",
            "Data columns (total 37 columns):\n",
            " #   Column                           Dtype  \n",
            "---  ------                           -----  \n",
            " 0   Year                             int64  \n",
            " 1   Quarter                          int64  \n",
            " 2   Month                            int64  \n",
            " 3   DayofMonth                       int64  \n",
            " 4   DayOfWeek                        int64  \n",
            " 5   FlightDate                       object \n",
            " 6   Reporting_Airline                object \n",
            " 7   Tail_Number                      object \n",
            " 8   Flight_Number_Reporting_Airline  int64  \n",
            " 9   Origin                           object \n",
            " 10  Dest                             object \n",
            " 11  DepTime                          float64\n",
            " 12  DepDelay                         float64\n",
            " 13  TaxiOut                          float64\n",
            " 14  WheelsOff                        float64\n",
            " 15  WheelsOn                         float64\n",
            " 16  TaxiIn                           float64\n",
            " 17  CRSArrTime                       int64  \n",
            " 18  ArrTime                          float64\n",
            " 19  ArrDelay                         float64\n",
            " 20  ArrDel15                         float64\n",
            " 21  Cancelled                        float64\n",
            " 22  Diverted                         float64\n",
            " 23  CRSElapsedTime                   float64\n",
            " 24  ActualElapsedTime                float64\n",
            " 25  AirTime                          float64\n",
            " 26  Flights                          float64\n",
            " 27  Distance                         float64\n",
            " 28  CarrierDelay                     float64\n",
            " 29  WeatherDelay                     float64\n",
            " 30  NASDelay                         float64\n",
            " 31  SecurityDelay                    float64\n",
            " 32  LateAircraftDelay                float64\n",
            " 33  Carrier                          object \n",
            " 34  Full-time                        float64\n",
            " 35  Part-time                        float64\n",
            " 36  Grand Total                      float64\n",
            "dtypes: float64(24), int64(7), object(6)\n",
            "memory usage: 4.8+ GB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwKwQ8Tcq2Sn",
        "outputId": "e07bbd1a-f2f7-4a5f-bcd2-79e689657dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique origin airports: 378\n",
            "Number of unique destination airports: 379\n"
          ]
        }
      ],
      "source": [
        "# Number of unique values in the 'Origin' column\n",
        "unique_origins = data['Origin'].nunique()\n",
        "print(\"Number of unique origin airports:\", unique_origins)\n",
        "\n",
        "# Number of unique values in the 'Dest' column\n",
        "unique_destinations = data['Dest'].nunique()\n",
        "print(\"Number of unique destination airports:\", unique_destinations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYJshR1Sq2Sn",
        "outputId": "3bc099f2-e051-454c-ac9a-8a67e702f966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Origin Airports Distribution:\n",
            " Other    11570431\n",
            "ATL        886549\n",
            "DFW        782947\n",
            "DEN        731279\n",
            "ORD        691163\n",
            "CLT        564569\n",
            "LAX        489642\n",
            "PHX        448145\n",
            "SEA        443246\n",
            "LAS        429452\n",
            "MCO        375453\n",
            "Name: Top_Origin, dtype: int64\n",
            "\n",
            "Top Destination Airports Distribution:\n",
            " Other    11570832\n",
            "ATL        886484\n",
            "DFW        782869\n",
            "DEN        731189\n",
            "ORD        691113\n",
            "CLT        564520\n",
            "LAX        489595\n",
            "PHX        448084\n",
            "SEA        443211\n",
            "LAS        429519\n",
            "MCO        375460\n",
            "Name: Top_Dest, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Top ten origin and destination airports\n",
        "top_ten_origins = data['Origin'].value_counts().head(10).index\n",
        "top_ten_destinations = data['Dest'].value_counts().head(10).index\n",
        "\n",
        "# Categorize all other airports as 'Other' in new columns\n",
        "data['Top_Origin'] = data['Origin'].apply(lambda x: x if x in top_ten_origins else 'Other')\n",
        "data['Top_Dest'] = data['Dest'].apply(lambda x: x if x in top_ten_destinations else 'Other')\n",
        "\n",
        "# Checking the distribution of the new columns\n",
        "print(\"Top Origin Airports Distribution:\\n\", data['Top_Origin'].value_counts())\n",
        "print(\"\\nTop Destination Airports Distribution:\\n\", data['Top_Dest'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgKmRMxvq2Sn",
        "outputId": "bebd2e43-7db1-4890-d2fe-6c077e91cb4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered Top Origin Airports Distribution:\n",
            " LAX    145590\n",
            "DEN    145335\n",
            "ORD    127780\n",
            "LAS    127311\n",
            "ATL    127034\n",
            "DFW    121895\n",
            "PHX    117274\n",
            "SEA    108540\n",
            "MCO     86840\n",
            "CLT     78146\n",
            "Name: Top_Origin, dtype: int64\n",
            "\n",
            "Filtered Top Destination Airports Distribution:\n",
            " LAX    145672\n",
            "DEN    145207\n",
            "ORD    127583\n",
            "LAS    127282\n",
            "ATL    127016\n",
            "DFW    121917\n",
            "PHX    117337\n",
            "SEA    108586\n",
            "MCO     86923\n",
            "CLT     78222\n",
            "Name: Top_Dest, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Exclude rows where 'Top_Origin' or 'Top_Dest' is 'Other'\n",
        "filtered_data = data[(data['Top_Origin'] != 'Other') & (data['Top_Dest'] != 'Other')]\n",
        "\n",
        "# Checking distribution\n",
        "print(\"Filtered Top Origin Airports Distribution:\\n\", filtered_data['Top_Origin'].value_counts())\n",
        "print(\"\\nFiltered Top Destination Airports Distribution:\\n\", filtered_data['Top_Dest'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaNw5YiSq2Sn",
        "outputId": "960de23b-0bef-4943-be21-ad59723ebefa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17412871    0.0\n",
            "17412872    0.0\n",
            "17412873    0.0\n",
            "17412874    0.0\n",
            "17412875    NaN\n",
            "Name: ArrDel15, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(data['ArrDel15'].tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG2csqWTq2Sn",
        "outputId": "1241a7ff-e9d5-4fe3-b570-3b2ecdaffedb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned Dataset Shape: (2813734, 12)\n"
          ]
        }
      ],
      "source": [
        "# List of features to include, plus the target variable\n",
        "features = ['Top_Origin', 'Top_Dest','DepTime', 'DepDelay', 'Distance', 'ArrTime', 'CarrierDelay',\n",
        "            'WeatherDelay', 'Full-time', 'Part-time', 'SecurityDelay', 'ArrDel15']\n",
        "\n",
        "# Filter the dataset to include only the selected features and target variable\n",
        "selected_data = data[features]\n",
        "\n",
        "# Drop rows with NaN values in any of the selected columns\n",
        "selected_data_cleaned = selected_data.dropna()\n",
        "\n",
        "# Print the shape of the cleaned dataset\n",
        "print(\"Cleaned Dataset Shape:\", selected_data_cleaned.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA7PouJWq2Sn",
        "outputId": "e22be12d-267b-41be-a124-c41972d0d319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    DepTime  DepDelay  Distance  ArrTime  CarrierDelay  WeatherDelay  \\\n",
            "14   2019.0      39.0    1133.0   2251.0           2.0           0.0   \n",
            "23    854.0      -6.0     728.0   1201.0           0.0           0.0   \n",
            "44   1311.0      56.0     728.0   1517.0          54.0           0.0   \n",
            "79   1448.0      -7.0    1121.0   1917.0           0.0           0.0   \n",
            "85   1542.0      57.0    1121.0   1841.0          31.0           0.0   \n",
            "\n",
            "    Full-time  Part-time  SecurityDelay  ArrDel15  ...  Dest_CLT  Dest_DEN  \\\n",
            "14    16738.0     4860.0            0.0       1.0  ...         0         0   \n",
            "23    16738.0     4860.0            0.0       1.0  ...         1         0   \n",
            "44    16738.0     4860.0            0.0       1.0  ...         0         0   \n",
            "79    16738.0     4860.0            0.0       1.0  ...         0         0   \n",
            "85    16738.0     4860.0            0.0       1.0  ...         0         0   \n",
            "\n",
            "    Dest_DFW  Dest_LAS  Dest_LAX  Dest_MCO  Dest_ORD  Dest_Other  Dest_PHX  \\\n",
            "14         0         0         0         0         0           1         0   \n",
            "23         0         0         0         0         0           0         0   \n",
            "44         0         0         0         0         0           1         0   \n",
            "79         0         0         0         1         0           0         0   \n",
            "85         0         0         0         1         0           0         0   \n",
            "\n",
            "    Dest_SEA  \n",
            "14         0  \n",
            "23         0  \n",
            "44         0  \n",
            "79         0  \n",
            "85         0  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# One-hot encode 'Top_Origin' and 'Top_Dest'\n",
        "one_hot_origin = pd.get_dummies(selected_data_cleaned['Top_Origin'], prefix='Origin')\n",
        "one_hot_dest = pd.get_dummies(selected_data_cleaned['Top_Dest'], prefix='Dest')\n",
        "\n",
        "# Concatenate the one-hot encoded columns back to the DataFrame\n",
        "selected_data_encoded = pd.concat([selected_data_cleaned, one_hot_origin, one_hot_dest], axis=1)\n",
        "\n",
        "# Drop the original 'Top_Origin' and 'Top_Dest' columns\n",
        "selected_data_encoded.drop(['Top_Origin', 'Top_Dest'], axis=1, inplace=True)\n",
        "\n",
        "# Check the first few rows of the dataset\n",
        "print(selected_data_encoded.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3lvChmYq2Sn",
        "outputId": "15e43817-c1f1-4ee5-f64d-ca3228cd7981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded Dataset Shape: (2813734, 32)\n"
          ]
        }
      ],
      "source": [
        "print(\"Encoded Dataset Shape:\", selected_data_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKmGPtsHq2Sn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = selected_data_encoded.drop('ArrDel15', axis=1)\n",
        "y = selected_data_encoded['ArrDel15']\n",
        "\n",
        "# Splitting the dataset into train, validation, and test sets (70%, 15%, 15%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ogq_SmNq2Sn",
        "outputId": "5c704e3d-4117-468f-fd7b-aaa81ddd9dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Types:\n",
            " DepTime          float64\n",
            "DepDelay         float64\n",
            "Distance         float64\n",
            "ArrTime          float64\n",
            "CarrierDelay     float64\n",
            "WeatherDelay     float64\n",
            "Full-time        float64\n",
            "Part-time        float64\n",
            "SecurityDelay    float64\n",
            "Origin_ATL         uint8\n",
            "Origin_CLT         uint8\n",
            "Origin_DEN         uint8\n",
            "Origin_DFW         uint8\n",
            "Origin_LAS         uint8\n",
            "Origin_LAX         uint8\n",
            "Origin_MCO         uint8\n",
            "Origin_ORD         uint8\n",
            "Origin_Other       uint8\n",
            "Origin_PHX         uint8\n",
            "Origin_SEA         uint8\n",
            "Dest_ATL           uint8\n",
            "Dest_CLT           uint8\n",
            "Dest_DEN           uint8\n",
            "Dest_DFW           uint8\n",
            "Dest_LAS           uint8\n",
            "Dest_LAX           uint8\n",
            "Dest_MCO           uint8\n",
            "Dest_ORD           uint8\n",
            "Dest_Other         uint8\n",
            "Dest_PHX           uint8\n",
            "Dest_SEA           uint8\n",
            "dtype: object\n",
            "\n",
            "Unique Values Count for Numerical Columns:\n",
            "DepTime: 1440 unique values\n",
            "DepDelay: 1802 unique values\n",
            "Distance: 1680 unique values\n",
            "ArrTime: 1440 unique values\n",
            "CarrierDelay: 1667 unique values\n",
            "WeatherDelay: 1188 unique values\n",
            "Full-time: 575 unique values\n",
            "Part-time: 478 unique values\n",
            "SecurityDelay: 259 unique values\n",
            "Origin_ATL: 2 unique values\n",
            "Origin_CLT: 2 unique values\n",
            "Origin_DEN: 2 unique values\n",
            "Origin_DFW: 2 unique values\n",
            "Origin_LAS: 2 unique values\n",
            "Origin_LAX: 2 unique values\n",
            "Origin_MCO: 2 unique values\n",
            "Origin_ORD: 2 unique values\n",
            "Origin_Other: 2 unique values\n",
            "Origin_PHX: 2 unique values\n",
            "Origin_SEA: 2 unique values\n",
            "Dest_ATL: 2 unique values\n",
            "Dest_CLT: 2 unique values\n",
            "Dest_DEN: 2 unique values\n",
            "Dest_DFW: 2 unique values\n",
            "Dest_LAS: 2 unique values\n",
            "Dest_LAX: 2 unique values\n",
            "Dest_MCO: 2 unique values\n",
            "Dest_ORD: 2 unique values\n",
            "Dest_Other: 2 unique values\n",
            "Dest_PHX: 2 unique values\n",
            "Dest_SEA: 2 unique values\n",
            "\n",
            "Descriptive Statistics for Numerical Columns:\n",
            "            DepTime      DepDelay      Distance       ArrTime  CarrierDelay  \\\n",
            "count  1.969613e+06  1.969613e+06  1.969613e+06  1.969613e+06  1.969613e+06   \n",
            "mean   1.510076e+03  6.247384e+01  8.446506e+02  1.550419e+03  2.671113e+01   \n",
            "std    4.958463e+02  9.695168e+01  5.834110e+02  6.221459e+02  7.440218e+01   \n",
            "min    1.000000e+00 -6.000000e+01  2.900000e+01  1.000000e+00  0.000000e+00   \n",
            "25%    1.141000e+03  1.800000e+01  4.070000e+02  1.222000e+03  0.000000e+00   \n",
            "50%    1.551000e+03  3.900000e+01  7.310000e+02  1.704000e+03  6.000000e+00   \n",
            "75%    1.916000e+03  7.500000e+01  1.076000e+03  2.032000e+03  2.600000e+01   \n",
            "max    2.400000e+03  3.890000e+03  5.812000e+03  2.400000e+03  3.864000e+03   \n",
            "\n",
            "       WeatherDelay     Full-time     Part-time  SecurityDelay    Origin_ATL  \\\n",
            "count  1.969613e+06  1.969613e+06  1.969613e+06   1.969613e+06  1.969613e+06   \n",
            "mean   4.135855e+00  4.196806e+04  3.998004e+03   1.720841e-01  4.249007e-02   \n",
            "std    3.280074e+01  3.290014e+04  4.622785e+03   3.877144e+00  2.017045e-01   \n",
            "min    0.000000e+00  2.357000e+03  0.000000e+00   0.000000e+00  0.000000e+00   \n",
            "25%    0.000000e+00  1.099600e+04  7.400000e+02   0.000000e+00  0.000000e+00   \n",
            "50%    0.000000e+00  5.319700e+04  1.715000e+03   0.000000e+00  0.000000e+00   \n",
            "75%    0.000000e+00  6.869900e+04  4.805000e+03   0.000000e+00  0.000000e+00   \n",
            "max    2.363000e+03  9.737300e+04  1.642400e+04   1.245000e+03  1.000000e+00   \n",
            "\n",
            "       ...      Dest_CLT      Dest_DEN      Dest_DFW      Dest_LAS  \\\n",
            "count  ...  1.969613e+06  1.969613e+06  1.969613e+06  1.969613e+06   \n",
            "mean   ...  2.629349e-02  4.271397e-02  4.853390e-02  2.845381e-02   \n",
            "std    ...  1.600067e-01  2.022116e-01  2.148916e-01  1.662655e-01   \n",
            "min    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "25%    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "50%    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "75%    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "max    ...  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
            "\n",
            "           Dest_LAX      Dest_MCO      Dest_ORD    Dest_Other      Dest_PHX  \\\n",
            "count  1.969613e+06  1.969613e+06  1.969613e+06  1.969613e+06  1.969613e+06   \n",
            "mean   2.636711e-02  2.770037e-02  3.578013e-02  6.799244e-01  2.427685e-02   \n",
            "std    1.602245e-01  1.641130e-01  1.857416e-01  4.665054e-01  1.539074e-01   \n",
            "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "50%    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
            "75%    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
            "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
            "\n",
            "           Dest_SEA  \n",
            "count  1.969613e+06  \n",
            "mean   2.257652e-02  \n",
            "std    1.485491e-01  \n",
            "min    0.000000e+00  \n",
            "25%    0.000000e+00  \n",
            "50%    0.000000e+00  \n",
            "75%    0.000000e+00  \n",
            "max    1.000000e+00  \n",
            "\n",
            "[8 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "# Display data types of each column\n",
        "print(\"Data Types:\\n\", X_train.dtypes)\n",
        "\n",
        "# Display unique values count for numerical columns\n",
        "print(\"\\nUnique Values Count for Numerical Columns:\")\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype != 'object':\n",
        "        print(f\"{col}: {X_train[col].nunique()} unique values\")\n",
        "\n",
        "# Descriptive statistics for numerical columns\n",
        "print(\"\\nDescriptive Statistics for Numerical Columns:\")\n",
        "print(X_train.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "324SOk6Hq2So"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Columns to scale\n",
        "columns_to_scale = ['DepTime', 'DepDelay', 'Distance', 'ArrTime',\n",
        "                    'CarrierDelay', 'WeatherDelay', 'Full-time',\n",
        "                    'Part-time', 'SecurityDelay']\n",
        "\n",
        "# Apply the scaler to the training set\n",
        "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
        "\n",
        "# Apply the same scaler to the validation and test sets\n",
        "X_validation[columns_to_scale] = scaler.transform(X_validation[columns_to_scale])\n",
        "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ6EgZdMq2So",
        "outputId": "48271990-f93a-4e94-ae7c-501582bfe359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                320       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 331 (1.29 KB)\n",
            "Trainable params: 331 (1.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))  # Hidden layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hggHPtd1q2So",
        "outputId": "f74de469-4b02-48e0-de78-9db59f748265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "61551/61551 [==============================] - 26s 423us/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 2.5075e-09 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "61551/61551 [==============================] - 26s 425us/step - loss: 2.2294e-09 - accuracy: 1.0000 - val_loss: 2.0540e-09 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "61551/61551 [==============================] - 26s 419us/step - loss: 1.9619e-09 - accuracy: 1.0000 - val_loss: 1.8821e-09 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "61551/61551 [==============================] - 26s 420us/step - loss: 1.8216e-09 - accuracy: 1.0000 - val_loss: 1.7758e-09 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "61551/61551 [==============================] - 26s 415us/step - loss: 1.7395e-09 - accuracy: 1.0000 - val_loss: 1.7044e-09 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "61551/61551 [==============================] - 26s 427us/step - loss: 1.6771e-09 - accuracy: 1.0000 - val_loss: 1.6545e-09 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "61551/61551 [==============================] - 27s 442us/step - loss: 1.6274e-09 - accuracy: 1.0000 - val_loss: 1.6084e-09 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "61551/61551 [==============================] - 26s 416us/step - loss: 1.5882e-09 - accuracy: 1.0000 - val_loss: 1.5766e-09 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "61551/61551 [==============================] - 28s 458us/step - loss: 1.5609e-09 - accuracy: 1.0000 - val_loss: 1.5528e-09 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "61551/61551 [==============================] - 27s 443us/step - loss: 1.5404e-09 - accuracy: 1.0000 - val_loss: 1.5306e-09 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_validation, y_validation))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQqKCPF0q2So",
        "outputId": "d56a6127-c659-4db0-e406-c1b0d7d94af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                320       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 441 (1.72 KB)\n",
            "Trainable params: 441 (1.72 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "n_features = X_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First hidden layer with L2 regularization\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,), kernel_regularizer=l2(0.001)))\n",
        "\n",
        "# Dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(10, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "\n",
        "# Another dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeLlbjAvq2So",
        "outputId": "52fa9b4e-0a60-49e5-a8cc-1ff3b9f4c24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "61551/61551 [==============================] - 29s 466us/step - loss: 1.2744e-09 - accuracy: 1.0000 - val_loss: 1.6278e-19 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "61551/61551 [==============================] - 28s 455us/step - loss: 7.0020e-10 - accuracy: 1.0000 - val_loss: 9.2887e-20 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=2, batch_size=32, validation_data=(X_validation, y_validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23791QFXq2So",
        "outputId": "337bd1cc-63ed-4b06-b31c-24fb579f55e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate  \\\n",
            "0  2020.0      1.0    1.0         1.0        3.0  2020-01-01   \n",
            "1  2020.0      1.0    1.0         1.0        3.0  2020-01-01   \n",
            "2  2020.0      1.0    1.0         1.0        3.0  2020-01-01   \n",
            "3  2020.0      1.0    1.0         1.0        3.0  2020-01-01   \n",
            "4  2020.0      1.0    1.0         1.0        3.0  2020-01-01   \n",
            "\n",
            "  Reporting_Airline Tail_Number  Flight_Number_Reporting_Airline Origin  ...  \\\n",
            "0                AA      N407AN                            664.0    KOA  ...   \n",
            "1                9E      N297PQ                           5270.0    LFT  ...   \n",
            "2                WN      N963WN                           1395.0    CMH  ...   \n",
            "3                AA      N891NN                            137.0    TUS  ...   \n",
            "4                AA      N807AW                           2189.0    SAT  ...   \n",
            "\n",
            "  Full-time  Part-time  Grand Total  Origin_Windspeed  Origin_Precip  \\\n",
            "0   95612.0    11840.0     107452.0               3.0           0.08   \n",
            "1    4741.0      103.0       4844.0               0.0           0.00   \n",
            "2   59914.0     2302.0      62216.0              12.0           0.00   \n",
            "3   95612.0    11840.0     107452.0               7.0           0.00   \n",
            "4   95612.0    11840.0     107452.0               0.0           0.00   \n",
            "\n",
            "   Dest_Windspeed  Dest_Precip  dest_ianaTimeZone  origin_ianaTimeZone  \\\n",
            "0             0.0          0.0    America/Phoenix  America/Los_Angeles   \n",
            "1             5.0          0.0   America/New_York      America/Chicago   \n",
            "2             7.0          0.0    America/Chicago     America/New_York   \n",
            "3             8.0          0.0    America/Chicago      America/Phoenix   \n",
            "4            12.0          0.0    America/Chicago      America/Chicago   \n",
            "\n",
            "   Aircraft_Daily_Flight_Count  \n",
            "0                            1  \n",
            "1                            1  \n",
            "2                            1  \n",
            "3                            1  \n",
            "4                            1  \n",
            "\n",
            "[5 rows x 36 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 343120 entries, 0 to 343119\n",
            "Data columns (total 36 columns):\n",
            " #   Column                           Non-Null Count   Dtype  \n",
            "---  ------                           --------------   -----  \n",
            " 0   Year                             343120 non-null  float64\n",
            " 1   Quarter                          343120 non-null  float64\n",
            " 2   Month                            343120 non-null  float64\n",
            " 3   DayofMonth                       343120 non-null  float64\n",
            " 4   DayOfWeek                        343120 non-null  float64\n",
            " 5   FlightDate                       343120 non-null  object \n",
            " 6   Reporting_Airline                343120 non-null  object \n",
            " 7   Tail_Number                      343120 non-null  object \n",
            " 8   Flight_Number_Reporting_Airline  343120 non-null  float64\n",
            " 9   Origin                           343120 non-null  object \n",
            " 10  Dest                             343120 non-null  object \n",
            " 11  DepTime                          343120 non-null  float64\n",
            " 12  DepDelay                         343120 non-null  float64\n",
            " 13  TaxiOut                          343120 non-null  float64\n",
            " 14  WheelsOff                        343120 non-null  float64\n",
            " 15  WheelsOn                         343120 non-null  float64\n",
            " 16  TaxiIn                           343120 non-null  float64\n",
            " 17  CRSArrTime                       343120 non-null  float64\n",
            " 18  ArrTime                          343120 non-null  float64\n",
            " 19  ArrDelay                         343120 non-null  float64\n",
            " 20  ArrDel15                         343120 non-null  float64\n",
            " 21  CRSElapsedTime                   343120 non-null  float64\n",
            " 22  ActualElapsedTime                343120 non-null  float64\n",
            " 23  AirTime                          343120 non-null  float64\n",
            " 24  Distance                         343120 non-null  float64\n",
            " 25  Carrier                          343120 non-null  object \n",
            " 26  Full-time                        343120 non-null  float64\n",
            " 27  Part-time                        343120 non-null  float64\n",
            " 28  Grand Total                      343120 non-null  float64\n",
            " 29  Origin_Windspeed                 343120 non-null  float64\n",
            " 30  Origin_Precip                    343120 non-null  float64\n",
            " 31  Dest_Windspeed                   343120 non-null  float64\n",
            " 32  Dest_Precip                      343120 non-null  float64\n",
            " 33  dest_ianaTimeZone                343120 non-null  object \n",
            " 34  origin_ianaTimeZone              343120 non-null  object \n",
            " 35  Aircraft_Daily_Flight_Count      343120 non-null  int64  \n",
            "dtypes: float64(27), int64(1), object(8)\n",
            "memory usage: 94.2+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "file_path = '/Users/anovayoungers/Downloads/flight_data_weather.csv'\n",
        "\n",
        "weather_data = pd.read_csv(file_path)\n",
        "\n",
        "print(weather_data.head())\n",
        "\n",
        "print(weather_data.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkNGJgtDq2So"
      },
      "outputs": [],
      "source": [
        "# Selecting the relevant columns\n",
        "columns_to_use = ['Origin', 'Dest', 'DepTime', 'DepDelay', 'TaxiOut', 'WheelsOff',\n",
        "                'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDel15',\n",
        "                'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Distance',\n",
        "                'Carrier', 'Full-time', 'Part-time', 'Origin_Windspeed',\n",
        "                'Origin_Precip', 'Dest_Windspeed', 'Dest_Precip']\n",
        "\n",
        "# Copy the dataset to avoid SettingWithCopyWarning\n",
        "selected_data = weather_data[columns_to_use].copy()\n",
        "\n",
        "# Top ten origin and destination airports\n",
        "top_ten_origins = selected_data['Origin'].value_counts().head(10).index\n",
        "top_ten_destinations = selected_data['Dest'].value_counts().head(10).index\n",
        "\n",
        "# Categorize all other airports as 'Other' using .loc\n",
        "selected_data.loc[:, 'Top_Origin'] = selected_data['Origin'].apply(lambda x: x if x in top_ten_origins else 'Other')\n",
        "selected_data.loc[:, 'Top_Dest'] = selected_data['Dest'].apply(lambda x: x if x in top_ten_destinations else 'Other')\n",
        "\n",
        "# One-hot encode the top origin and destination airports with unique labels\n",
        "one_hot_origin = pd.get_dummies(selected_data['Top_Origin'], prefix='Weather_Origin')\n",
        "one_hot_dest = pd.get_dummies(selected_data['Top_Dest'], prefix='Weather_Dest')\n",
        "\n",
        "# Concatenate the one-hot encoded columns back to the DataFrame\n",
        "selected_data_encoded = pd.concat([selected_data, one_hot_origin, one_hot_dest], axis=1)\n",
        "\n",
        "# Drop the original and 'Other' categories from 'Top_Origin' and 'Top_Dest'\n",
        "selected_data_encoded.drop(['Origin', 'Dest', 'Top_Origin', 'Top_Dest', 'Weather_Origin_Other', 'Weather_Dest_Other'], axis=1, inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_data_encoded.drop('ArrDel15', axis=1)\n",
        "y = selected_data_encoded['ArrDel15']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhVYOLWuq2So"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into train and temporary sets (70% train, 30% temp)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Splitting the temporary set into validation and test sets (each 15% of the total data)\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3qC-QZ-q2So",
        "outputId": "73d6fc7c-93fe-41c6-b029-28fff51b551f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique Values in Numerical Columns:\n",
            "DepTime: 1363 unique values\n",
            "DepDelay: 1076 unique values\n",
            "TaxiOut: 165 unique values\n",
            "WheelsOff: 1363 unique values\n",
            "WheelsOn: 1437 unique values\n",
            "TaxiIn: 152 unique values\n",
            "CRSArrTime: 1320 unique values\n",
            "ArrTime: 1432 unique values\n",
            "CRSElapsedTime: 535 unique values\n",
            "ActualElapsedTime: 574 unique values\n",
            "AirTime: 554 unique values\n",
            "Distance: 1547 unique values\n",
            "Full-time: 575 unique values\n",
            "Part-time: 478 unique values\n",
            "Origin_Windspeed: 42 unique values\n",
            "Origin_Precip: 122 unique values\n",
            "Dest_Windspeed: 46 unique values\n",
            "Dest_Precip: 127 unique values\n",
            "\n",
            "Descriptive Statistics for Numerical Columns:\n",
            "             DepTime       DepDelay        TaxiOut      WheelsOff  \\\n",
            "count  240184.000000  240184.000000  240184.000000  240184.000000   \n",
            "mean     1386.751732      28.845302      17.971459    1410.157858   \n",
            "std       492.749936      74.977514      11.945688     495.322629   \n",
            "min         1.000000     -60.000000       1.000000       1.000000   \n",
            "25%      1003.000000      -4.000000      11.000000    1020.000000   \n",
            "50%      1412.000000       2.000000      14.000000    1426.000000   \n",
            "75%      1806.000000      37.000000      20.000000    1822.000000   \n",
            "max      2400.000000    2105.000000     218.000000    2400.000000   \n",
            "\n",
            "            WheelsOn         TaxiIn     CRSArrTime        ArrTime  \\\n",
            "count  240184.000000  240184.000000  240184.000000  240184.000000   \n",
            "mean     1504.406247       7.974220    1533.954739    1506.812061   \n",
            "std       539.683586       7.657283     498.480100     546.273973   \n",
            "min         1.000000       1.000000       1.000000       1.000000   \n",
            "25%      1128.000000       4.000000    1142.000000    1131.000000   \n",
            "50%      1548.000000       6.000000    1555.000000    1551.000000   \n",
            "75%      1934.000000       9.000000    1936.000000    1939.000000   \n",
            "max      2400.000000     251.000000    2359.000000    2400.000000   \n",
            "\n",
            "       CRSElapsedTime  ActualElapsedTime  ...  Weather_Dest_ATL  \\\n",
            "count   240184.000000      240184.000000  ...     240184.000000   \n",
            "mean       141.159636         138.990491  ...          0.049271   \n",
            "std         68.253900          69.795677  ...          0.216433   \n",
            "min         22.000000          21.000000  ...          0.000000   \n",
            "25%         90.000000          88.000000  ...          0.000000   \n",
            "50%        127.000000         125.000000  ...          0.000000   \n",
            "75%        171.000000         171.000000  ...          0.000000   \n",
            "max        695.000000         716.000000  ...          1.000000   \n",
            "\n",
            "       Weather_Dest_CLT  Weather_Dest_DEN  Weather_Dest_DFW  Weather_Dest_LAS  \\\n",
            "count     240184.000000     240184.000000     240184.000000     240184.000000   \n",
            "mean           0.032829          0.044649          0.054179          0.026609   \n",
            "std            0.178189          0.206533          0.226372          0.160937   \n",
            "min            0.000000          0.000000          0.000000          0.000000   \n",
            "25%            0.000000          0.000000          0.000000          0.000000   \n",
            "50%            0.000000          0.000000          0.000000          0.000000   \n",
            "75%            0.000000          0.000000          0.000000          0.000000   \n",
            "max            1.000000          1.000000          1.000000          1.000000   \n",
            "\n",
            "       Weather_Dest_LAX  Weather_Dest_MCO  Weather_Dest_ORD  Weather_Dest_PHX  \\\n",
            "count     240184.000000     240184.000000     240184.000000     240184.000000   \n",
            "mean           0.026909          0.022449          0.039715          0.025568   \n",
            "std            0.161816          0.148140          0.195290          0.157843   \n",
            "min            0.000000          0.000000          0.000000          0.000000   \n",
            "25%            0.000000          0.000000          0.000000          0.000000   \n",
            "50%            0.000000          0.000000          0.000000          0.000000   \n",
            "75%            0.000000          0.000000          0.000000          0.000000   \n",
            "max            1.000000          1.000000          1.000000          1.000000   \n",
            "\n",
            "       Weather_Dest_SEA  \n",
            "count     240184.000000  \n",
            "mean           0.024481  \n",
            "std            0.154538  \n",
            "min            0.000000  \n",
            "25%            0.000000  \n",
            "50%            0.000000  \n",
            "75%            0.000000  \n",
            "max            1.000000  \n",
            "\n",
            "[8 rows x 38 columns]\n"
          ]
        }
      ],
      "source": [
        "# Print unique value counts for numerical columns\n",
        "print(\"Unique Values in Numerical Columns:\")\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype != 'object' and X_train[col].nunique() > 10:\n",
        "        print(f\"{col}: {X_train[col].nunique()} unique values\")\n",
        "\n",
        "# Print descriptive statistics for numerical columns\n",
        "print(\"\\nDescriptive Statistics for Numerical Columns:\")\n",
        "print(X_train.describe())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW-lx6ztq2So"
      },
      "outputs": [],
      "source": [
        "# Drop the 'Carrier' column from the training set\n",
        "X_train = X_train.drop('Carrier', axis=1)\n",
        "\n",
        "# Drop the 'Carrier' column from the validation set\n",
        "X_validation = X_validation.drop('Carrier', axis=1)\n",
        "\n",
        "# Drop the 'Carrier' column from the test set\n",
        "X_test = X_test.drop('Carrier', axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHiYJ4kPq2So"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Columns to scale\n",
        "columns_to_scale = ['DepTime', 'DepDelay', 'TaxiOut', 'WheelsOff', 'WheelsOn',\n",
        "                    'TaxiIn', 'CRSArrTime', 'ArrTime',\n",
        "                    'CRSElapsedTime', 'ActualElapsedTime',\n",
        "                    'AirTime', 'Distance', 'Full-time', 'Part-time',\n",
        "                    'Origin_Windspeed', 'Origin_Precip', 'Dest_Windspeed',\n",
        "                    'Dest_Precip']\n",
        "\n",
        "# Apply the scaler to the training set\n",
        "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
        "\n",
        "# Apply the scaler to the validation and test sets\n",
        "X_validation[columns_to_scale] = scaler.transform(X_validation[columns_to_scale])\n",
        "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEqSsMmUq2So",
        "outputId": "e684a1c0-f980-4130-b873-0c12fd710e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of columns in Training set: 38\n",
            "Number of columns in Validation set: 38\n",
            "Number of columns in Test set: 38\n",
            "\n",
            "First few rows of the Training set:\n",
            "         DepTime  DepDelay   TaxiOut  WheelsOff  WheelsOn    TaxiIn  \\\n",
            "104854  1.352105 -0.424732 -0.499885   1.402810  1.300012 -0.519013   \n",
            "55290   0.142564 -0.024611 -0.499885   0.199551  0.410600  1.831695   \n",
            "147232 -0.082703 -0.438070 -0.165036  -0.016470  1.112865 -0.519013   \n",
            "231940 -1.184684  0.455533  0.420951  -1.179351 -0.914253  1.048126   \n",
            "73572  -0.715885 -0.211334  0.672088  -0.626175 -0.541812 -0.649608   \n",
            "\n",
            "        CRSArrTime   ArrTime  CRSElapsedTime  ActualElapsedTime  ...  \\\n",
            "104854    1.382295  1.287247        0.085568          -0.028519  ...   \n",
            "55290     0.367208  0.441516        0.378593           0.458618  ...   \n",
            "147232    1.229832  1.102357        2.283250           1.776754  ...   \n",
            "231940   -1.245699 -0.878338       -0.119549           0.071774  ...   \n",
            "73572    -0.669947 -0.534187       -0.617690          -0.544311  ...   \n",
            "\n",
            "        Weather_Dest_ATL  Weather_Dest_CLT  Weather_Dest_DEN  \\\n",
            "104854                 0                 0                 0   \n",
            "55290                  0                 0                 0   \n",
            "147232                 0                 0                 0   \n",
            "231940                 0                 0                 0   \n",
            "73572                  0                 0                 0   \n",
            "\n",
            "        Weather_Dest_DFW  Weather_Dest_LAS  Weather_Dest_LAX  \\\n",
            "104854                 0                 0                 0   \n",
            "55290                  0                 0                 0   \n",
            "147232                 0                 0                 0   \n",
            "231940                 0                 0                 0   \n",
            "73572                  0                 0                 0   \n",
            "\n",
            "        Weather_Dest_MCO  Weather_Dest_ORD  Weather_Dest_PHX  Weather_Dest_SEA  \n",
            "104854                 0                 0                 0                 0  \n",
            "55290                  0                 0                 0                 0  \n",
            "147232                 0                 0                 0                 0  \n",
            "231940                 0                 0                 0                 0  \n",
            "73572                  0                 0                 0                 0  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "\n",
            "Summary Statistics of the Training set (for scaled columns):\n",
            "            DepTime      DepDelay       TaxiOut     WheelsOff      WheelsOn  \\\n",
            "count  2.401840e+05  2.401840e+05  2.401840e+05  2.401840e+05  2.401840e+05   \n",
            "mean   2.166678e-16 -2.860702e-17  1.526053e-16 -1.831204e-17 -1.816708e-16   \n",
            "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
            "min   -2.812288e+00 -1.184962e+00 -1.420721e+00 -2.844935e+00 -2.785724e+00   \n",
            "25%   -7.787977e-01 -4.380696e-01 -5.835975e-01 -7.876859e-01 -6.974587e-01   \n",
            "50%    5.123962e-02 -3.580454e-01 -3.324604e-01  3.198355e-02  8.077667e-02   \n",
            "75%    8.508355e-01  1.087621e-01  1.698140e-01  8.314641e-01  7.960121e-01   \n",
            "max    2.056318e+00  2.769042e+01  1.674487e+01  1.998383e+00  1.659483e+00   \n",
            "\n",
            "             TaxiIn    CRSArrTime       ArrTime  CRSElapsedTime  \\\n",
            "count  2.401840e+05  2.401840e+05  2.401840e+05    2.401840e+05   \n",
            "mean  -1.539069e-17  1.906198e-16 -9.675947e-17   -4.328772e-17   \n",
            "std    1.000002e+00  1.000002e+00  1.000002e+00    1.000002e+00   \n",
            "min   -9.107975e-01 -3.075264e+00 -2.756520e+00   -1.745833e+00   \n",
            "25%   -5.190128e-01 -7.863013e-01 -6.879567e-01   -7.495505e-01   \n",
            "50%   -2.578230e-01  4.221895e-02  8.088987e-02   -2.074558e-01   \n",
            "75%    1.339617e-01  8.065439e-01  7.911577e-01    4.371974e-01   \n",
            "max    3.173793e+01  1.655125e+00  1.635058e+00    8.114430e+00   \n",
            "\n",
            "       ActualElapsedTime  ...  Weather_Dest_ATL  Weather_Dest_CLT  \\\n",
            "count       2.401840e+05  ...     240184.000000     240184.000000   \n",
            "mean        8.599856e-17  ...          0.049271          0.032829   \n",
            "std         1.000002e+00  ...          0.216433          0.178189   \n",
            "min        -1.690516e+00  ...          0.000000          0.000000   \n",
            "25%        -7.305696e-01  ...          0.000000          0.000000   \n",
            "50%        -2.004497e-01  ...          0.000000          0.000000   \n",
            "75%         4.586183e-01  ...          0.000000          0.000000   \n",
            "max         8.267141e+00  ...          1.000000          1.000000   \n",
            "\n",
            "       Weather_Dest_DEN  Weather_Dest_DFW  Weather_Dest_LAS  Weather_Dest_LAX  \\\n",
            "count     240184.000000     240184.000000     240184.000000     240184.000000   \n",
            "mean           0.044649          0.054179          0.026609          0.026909   \n",
            "std            0.206533          0.226372          0.160937          0.161816   \n",
            "min            0.000000          0.000000          0.000000          0.000000   \n",
            "25%            0.000000          0.000000          0.000000          0.000000   \n",
            "50%            0.000000          0.000000          0.000000          0.000000   \n",
            "75%            0.000000          0.000000          0.000000          0.000000   \n",
            "max            1.000000          1.000000          1.000000          1.000000   \n",
            "\n",
            "       Weather_Dest_MCO  Weather_Dest_ORD  Weather_Dest_PHX  Weather_Dest_SEA  \n",
            "count     240184.000000     240184.000000     240184.000000     240184.000000  \n",
            "mean           0.022449          0.039715          0.025568          0.024481  \n",
            "std            0.148140          0.195290          0.157843          0.154538  \n",
            "min            0.000000          0.000000          0.000000          0.000000  \n",
            "25%            0.000000          0.000000          0.000000          0.000000  \n",
            "50%            0.000000          0.000000          0.000000          0.000000  \n",
            "75%            0.000000          0.000000          0.000000          0.000000  \n",
            "max            1.000000          1.000000          1.000000          1.000000  \n",
            "\n",
            "[8 rows x 38 columns]\n",
            "\n",
            "Data types of the Training set columns:\n",
            "DepTime               float64\n",
            "DepDelay              float64\n",
            "TaxiOut               float64\n",
            "WheelsOff             float64\n",
            "WheelsOn              float64\n",
            "TaxiIn                float64\n",
            "CRSArrTime            float64\n",
            "ArrTime               float64\n",
            "CRSElapsedTime        float64\n",
            "ActualElapsedTime     float64\n",
            "AirTime               float64\n",
            "Distance              float64\n",
            "Full-time             float64\n",
            "Part-time             float64\n",
            "Origin_Windspeed      float64\n",
            "Origin_Precip         float64\n",
            "Dest_Windspeed        float64\n",
            "Dest_Precip           float64\n",
            "Weather_Origin_ATL      uint8\n",
            "Weather_Origin_CLT      uint8\n",
            "Weather_Origin_DEN      uint8\n",
            "Weather_Origin_DFW      uint8\n",
            "Weather_Origin_LAS      uint8\n",
            "Weather_Origin_LAX      uint8\n",
            "Weather_Origin_MCO      uint8\n",
            "Weather_Origin_ORD      uint8\n",
            "Weather_Origin_PHX      uint8\n",
            "Weather_Origin_SEA      uint8\n",
            "Weather_Dest_ATL        uint8\n",
            "Weather_Dest_CLT        uint8\n",
            "Weather_Dest_DEN        uint8\n",
            "Weather_Dest_DFW        uint8\n",
            "Weather_Dest_LAS        uint8\n",
            "Weather_Dest_LAX        uint8\n",
            "Weather_Dest_MCO        uint8\n",
            "Weather_Dest_ORD        uint8\n",
            "Weather_Dest_PHX        uint8\n",
            "Weather_Dest_SEA        uint8\n",
            "dtype: object\n",
            "\n",
            "First few values of the target variable in Training set:\n",
            "104854    0.0\n",
            "55290     1.0\n",
            "147232    0.0\n",
            "231940    1.0\n",
            "73572     1.0\n",
            "Name: ArrDel15, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Check for consistency in column numbers\n",
        "print(\"Number of columns in Training set:\", X_train.shape[1])\n",
        "print(\"Number of columns in Validation set:\", X_validation.shape[1])\n",
        "print(\"Number of columns in Test set:\", X_test.shape[1])\n",
        "\n",
        "# Inspect the first few rows\n",
        "print(\"\\nFirst few rows of the Training set:\")\n",
        "print(X_train.head())\n",
        "\n",
        "# Summary statistics of the training set (for scaled columns)\n",
        "print(\"\\nSummary Statistics of the Training set (for scaled columns):\")\n",
        "print(X_train.describe())\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nData types of the Training set columns:\")\n",
        "print(X_train.dtypes)\n",
        "\n",
        "# Check the target variable format\n",
        "print(\"\\nFirst few values of the target variable in Training set:\")\n",
        "print(y_train.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esj9_sqXq2So",
        "outputId": "ef205f9b-5a08-43f4-a453-252c305420d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 128)               4992      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13313 (52.00 KB)\n",
            "Trainable params: 13313 (52.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Number of input features\n",
        "n_features = X_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(n_features,)))  # First hidden layer\n",
        "model.add(Dense(64, activation='relu'))  # Second hidden layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl7R0Edmq2So",
        "outputId": "8edec83a-372d-45a8-c51e-a8587f7e02d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "7506/7506 [==============================] - 4s 568us/step - loss: 0.0591 - accuracy: 0.9773 - val_loss: 0.0454 - val_accuracy: 0.9842\n",
            "Epoch 2/20\n",
            "7506/7506 [==============================] - 4s 560us/step - loss: 0.0264 - accuracy: 0.9896 - val_loss: 0.0333 - val_accuracy: 0.9869\n",
            "Epoch 3/20\n",
            "7506/7506 [==============================] - 4s 559us/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.0164 - val_accuracy: 0.9935\n",
            "Epoch 4/20\n",
            "7506/7506 [==============================] - 4s 559us/step - loss: 0.0203 - accuracy: 0.9922 - val_loss: 0.0156 - val_accuracy: 0.9941\n",
            "Epoch 5/20\n",
            "7506/7506 [==============================] - 4s 560us/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.0143 - val_accuracy: 0.9947\n",
            "Epoch 6/20\n",
            "7506/7506 [==============================] - 4s 563us/step - loss: 0.0175 - accuracy: 0.9931 - val_loss: 0.0196 - val_accuracy: 0.9923\n",
            "Epoch 7/20\n",
            "7506/7506 [==============================] - 4s 564us/step - loss: 0.0164 - accuracy: 0.9936 - val_loss: 0.0146 - val_accuracy: 0.9944\n",
            "Epoch 8/20\n",
            "7506/7506 [==============================] - 4s 563us/step - loss: 0.0159 - accuracy: 0.9938 - val_loss: 0.0137 - val_accuracy: 0.9947\n",
            "Epoch 9/20\n",
            "7506/7506 [==============================] - 4s 563us/step - loss: 0.0154 - accuracy: 0.9940 - val_loss: 0.0159 - val_accuracy: 0.9936\n",
            "Epoch 10/20\n",
            "7506/7506 [==============================] - 4s 568us/step - loss: 0.0149 - accuracy: 0.9941 - val_loss: 0.0232 - val_accuracy: 0.9903\n",
            "Epoch 11/20\n",
            "7506/7506 [==============================] - 4s 566us/step - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.0247 - val_accuracy: 0.9910\n",
            "Epoch 12/20\n",
            "7506/7506 [==============================] - 4s 566us/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.0120 - val_accuracy: 0.9957\n",
            "Epoch 13/20\n",
            "7506/7506 [==============================] - 4s 566us/step - loss: 0.0131 - accuracy: 0.9950 - val_loss: 0.0164 - val_accuracy: 0.9947\n",
            "Epoch 14/20\n",
            "7506/7506 [==============================] - 4s 567us/step - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.0135 - val_accuracy: 0.9950\n",
            "Epoch 15/20\n",
            "7506/7506 [==============================] - 4s 576us/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0101 - val_accuracy: 0.9966\n",
            "Epoch 16/20\n",
            "7506/7506 [==============================] - 4s 571us/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0125 - val_accuracy: 0.9951\n",
            "Epoch 17/20\n",
            "7506/7506 [==============================] - 4s 576us/step - loss: 0.0121 - accuracy: 0.9952 - val_loss: 0.0122 - val_accuracy: 0.9949\n",
            "Epoch 18/20\n",
            "7506/7506 [==============================] - 5s 625us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0162 - val_accuracy: 0.9934\n",
            "Epoch 19/20\n",
            "7506/7506 [==============================] - 5s 615us/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.0161 - val_accuracy: 0.9937\n",
            "Epoch 20/20\n",
            "7506/7506 [==============================] - 4s 572us/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.0136 - val_accuracy: 0.9948\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Initialize EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with EarlyStopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTzs7j3eq2Sp"
      },
      "source": [
        "Overfitting central!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGn_GV4Pq2Sp",
        "outputId": "a602aad9-2d6e-40d5-bd43-765e89e05a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 128)               4992      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13313 (52.00 KB)\n",
            "Trainable params: 13313 (52.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "\n",
        "# Redefine the model with dropout and regularization\n",
        "model = Sequential()\n",
        "\n",
        "# First hidden layer with L1_L2 regularization and dropout\n",
        "model.add(Dense(128, activation='relu', input_shape=(n_features,), kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
        "model.add(Dropout(0.3))  # Adjusted dropout\n",
        "\n",
        "# Second hidden layer with regularization and dropout\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer remains the same\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAx5Yc5uq2Sp",
        "outputId": "56653a59-5fd8-49fd-86fa-edc5fa4d8cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "7506/7506 [==============================] - 5s 628us/step - loss: 0.6471 - accuracy: 0.8003 - val_loss: 0.3680 - val_accuracy: 0.9330\n",
            "Epoch 2/20\n",
            "7506/7506 [==============================] - 5s 628us/step - loss: 0.4719 - accuracy: 0.8320 - val_loss: 0.3538 - val_accuracy: 0.9161\n",
            "Epoch 3/20\n",
            "7506/7506 [==============================] - 5s 616us/step - loss: 0.4542 - accuracy: 0.8366 - val_loss: 0.3891 - val_accuracy: 0.8745\n",
            "Epoch 4/20\n",
            "7506/7506 [==============================] - 5s 620us/step - loss: 0.4463 - accuracy: 0.8371 - val_loss: 0.4049 - val_accuracy: 0.8594\n",
            "Epoch 5/20\n",
            "7506/7506 [==============================] - 5s 617us/step - loss: 0.4426 - accuracy: 0.8366 - val_loss: 0.3819 - val_accuracy: 0.8729\n",
            "Epoch 6/20\n",
            "7506/7506 [==============================] - 5s 622us/step - loss: 0.4388 - accuracy: 0.8371 - val_loss: 0.3721 - val_accuracy: 0.8762\n",
            "Epoch 7/20\n",
            "7506/7506 [==============================] - 5s 618us/step - loss: 0.4361 - accuracy: 0.8371 - val_loss: 0.3482 - val_accuracy: 0.8960\n",
            "Epoch 8/20\n",
            "7506/7506 [==============================] - 5s 622us/step - loss: 0.4331 - accuracy: 0.8382 - val_loss: 0.3675 - val_accuracy: 0.8798\n",
            "Epoch 9/20\n",
            "7506/7506 [==============================] - 5s 646us/step - loss: 0.4304 - accuracy: 0.8392 - val_loss: 0.3487 - val_accuracy: 0.8892\n",
            "Epoch 10/20\n",
            "7506/7506 [==============================] - 5s 636us/step - loss: 0.4293 - accuracy: 0.8393 - val_loss: 0.2881 - val_accuracy: 0.9403\n",
            "Epoch 11/20\n",
            "7506/7506 [==============================] - 5s 638us/step - loss: 0.4284 - accuracy: 0.8391 - val_loss: 0.2882 - val_accuracy: 0.9365\n",
            "Epoch 12/20\n",
            "7506/7506 [==============================] - 5s 620us/step - loss: 0.4276 - accuracy: 0.8391 - val_loss: 0.2384 - val_accuracy: 0.9870\n",
            "Epoch 13/20\n",
            "7506/7506 [==============================] - 5s 647us/step - loss: 0.4278 - accuracy: 0.8387 - val_loss: 0.2434 - val_accuracy: 0.9792\n",
            "Epoch 14/20\n",
            "7506/7506 [==============================] - 5s 639us/step - loss: 0.4265 - accuracy: 0.8389 - val_loss: 0.2389 - val_accuracy: 0.9896\n",
            "Epoch 15/20\n",
            "7506/7506 [==============================] - 5s 637us/step - loss: 0.4166 - accuracy: 0.8459 - val_loss: 0.2078 - val_accuracy: 0.9784\n",
            "Epoch 16/20\n",
            "7506/7506 [==============================] - 5s 623us/step - loss: 0.2890 - accuracy: 0.9289 - val_loss: 0.1661 - val_accuracy: 0.9827\n",
            "Epoch 17/20\n",
            "7506/7506 [==============================] - 5s 627us/step - loss: 0.2842 - accuracy: 0.9327 - val_loss: 0.1785 - val_accuracy: 0.9868\n",
            "Epoch 18/20\n",
            "7506/7506 [==============================] - 5s 629us/step - loss: 0.2831 - accuracy: 0.9331 - val_loss: 0.1772 - val_accuracy: 0.9880\n",
            "Epoch 19/20\n",
            "7506/7506 [==============================] - 5s 631us/step - loss: 0.2797 - accuracy: 0.9343 - val_loss: 0.1589 - val_accuracy: 0.9866\n",
            "Epoch 20/20\n",
            "7506/7506 [==============================] - 5s 638us/step - loss: 0.2799 - accuracy: 0.9344 - val_loss: 0.1589 - val_accuracy: 0.9824\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Initialize EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkxma7nzq2Sp",
        "outputId": "68eae9ef-d0ea-4994-e040-a3c76577aef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1609/1609 [==============================] - 0s 288us/step - loss: 0.1575 - accuracy: 0.9835\n",
            "Test Loss: 0.1575, Test Accuracy: 98.35%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss: {:.4f}, Test Accuracy: {:.2f}%\".format(test_loss, test_accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqkeSzWaq2Sp"
      },
      "source": [
        "The model performs well on unseen data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}